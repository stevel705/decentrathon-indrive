#!/usr/bin/env python3
"""
–£—Ç–∏–ª–∏—Ç—ã –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –∞–Ω–Ω–æ—Ç–∞—Ü–∏—è–º–∏ YOLO
–°–æ–∑–¥–∞–Ω–∏–µ, –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –∏ –≤–∞–ª–∏–¥–∞—Ü–∏—è –∞–Ω–Ω–æ—Ç–∞—Ü–∏–π –¥–ª—è –¥–µ—Ç–µ–∫—Ü–∏–∏ –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–∏–π
"""

import os
import json
import xml.etree.ElementTree as ET
from pathlib import Path
from PIL import Image
import cv2
import numpy as np

# –ö–ª–∞—Å—Å—ã –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–∏–π
DAMAGE_CLASSES = {
    'damaged_door': 0,
    'damaged_window': 1, 
    'damaged_headlight': 2,
    'damaged_mirror': 3,
    'dent': 4,
    'damaged_hood': 5,
    'damaged_bumper': 6,
    'damaged_windshield': 7
}

def convert_coco_to_yolo(coco_json_path: str, images_dir: str, output_dir: str):
    """
    –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç COCO –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏ –≤ —Ñ–æ—Ä–º–∞—Ç YOLO
    
    Args:
        coco_json_path: –ü—É—Ç—å –∫ COCO JSON —Ñ–∞–π–ª—É
        images_dir: –ü–∞–ø–∫–∞ —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏
        output_dir: –ü–∞–ø–∫–∞ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è YOLO –∞–Ω–Ω–æ—Ç–∞—Ü–∏–π
    """
    
    with open(coco_json_path, 'r') as f:
        coco_data = json.load(f)
    
    # –°–æ–∑–¥–∞–µ–º –º–∞–ø–ø–∏–Ω–≥ ID –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∫ –∏–º–µ–Ω–∞–º —Ñ–∞–π–ª–æ–≤
    images = {img['id']: img for img in coco_data['images']}
    
    # –°–æ–∑–¥–∞–µ–º –º–∞–ø–ø–∏–Ω–≥ –∫–∞—Ç–µ–≥–æ—Ä–∏–π
    categories = {cat['id']: cat['name'] for cat in coco_data['categories']}
    
    os.makedirs(output_dir, exist_ok=True)
    
    # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏ –ø–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º
    annotations_by_image = {}
    for ann in coco_data['annotations']:
        image_id = ann['image_id']
        if image_id not in annotations_by_image:
            annotations_by_image[image_id] = []
        annotations_by_image[image_id].append(ann)
    
    # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –∫–∞–∂–¥–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
    for image_id, annotations in annotations_by_image.items():
        image_info = images[image_id]
        image_width = image_info['width']
        image_height = image_info['height']
        
        # –ò–º—è —Ñ–∞–π–ª–∞ –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏
        annotation_filename = Path(image_info['file_name']).stem + '.txt'
        annotation_path = os.path.join(output_dir, annotation_filename)
        
        yolo_annotations = []
        
        for ann in annotations:
            # COCO bbox: [x, y, width, height]
            x, y, w, h = ann['bbox']
            
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ YOLO —Ñ–æ—Ä–º–∞—Ç (—Ü–µ–Ω—Ç—Ä + —Ä–∞–∑–º–µ—Ä—ã, –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ)
            center_x = (x + w / 2) / image_width
            center_y = (y + h / 2) / image_height
            norm_width = w / image_width
            norm_height = h / image_height
            
            # –ü–æ–ª—É—á–∞–µ–º –∫–ª–∞—Å—Å
            category_name = categories[ann['category_id']]
            class_id = DAMAGE_CLASSES.get(category_name, -1)
            
            if class_id != -1:
                yolo_annotations.append(f"{class_id} {center_x:.6f} {center_y:.6f} {norm_width:.6f} {norm_height:.6f}")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏
        with open(annotation_path, 'w') as f:
            f.write('\n'.join(yolo_annotations))
        
        print(f"–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ: {annotation_filename} ({len(yolo_annotations)} –æ–±—ä–µ–∫—Ç–æ–≤)")

def convert_pascal_voc_to_yolo(xml_dir: str, output_dir: str):
    """
    –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç Pascal VOC XML –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏ –≤ —Ñ–æ—Ä–º–∞—Ç YOLO
    
    Args:
        xml_dir: –ü–∞–ø–∫–∞ —Å XML —Ñ–∞–π–ª–∞–º–∏
        output_dir: –ü–∞–ø–∫–∞ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è YOLO –∞–Ω–Ω–æ—Ç–∞—Ü–∏–π
    """
    
    os.makedirs(output_dir, exist_ok=True)
    
    for xml_file in Path(xml_dir).glob('*.xml'):
        tree = ET.parse(xml_file)
        root = tree.getroot()
        
        # –ü–æ–ª—É—á–∞–µ–º —Ä–∞–∑–º–µ—Ä—ã –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        size = root.find('size')
        width = int(size.find('width').text)
        height = int(size.find('height').text)
        
        yolo_annotations = []
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∂–¥—ã–π –æ–±—ä–µ–∫—Ç
        for obj in root.findall('object'):
            class_name = obj.find('name').text
            class_id = DAMAGE_CLASSES.get(class_name, -1)
            
            if class_id == -1:
                print(f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –∫–ª–∞—Å—Å: {class_name}")
                continue
            
            # –ü–æ–ª—É—á–∞–µ–º bounding box
            bbox = obj.find('bndbox')
            xmin = int(bbox.find('xmin').text)
            ymin = int(bbox.find('ymin').text)
            xmax = int(bbox.find('xmax').text)
            ymax = int(bbox.find('ymax').text)
            
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ YOLO —Ñ–æ—Ä–º–∞—Ç
            center_x = (xmin + xmax) / 2 / width
            center_y = (ymin + ymax) / 2 / height
            bbox_width = (xmax - xmin) / width
            bbox_height = (ymax - ymin) / height
            
            yolo_annotations.append(f"{class_id} {center_x:.6f} {center_y:.6f} {bbox_width:.6f} {bbox_height:.6f}")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏
        output_file = output_dir / f"{xml_file.stem}.txt"
        with open(output_file, 'w') as f:
            f.write('\n'.join(yolo_annotations))
        
        print(f"–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ: {xml_file.name} -> {output_file.name} ({len(yolo_annotations)} –æ–±—ä–µ–∫—Ç–æ–≤)")

def validate_yolo_annotations(images_dir: str, labels_dir: str):
    """
    –í–∞–ª–∏–¥–∏—Ä—É–µ—Ç YOLO –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏
    
    Args:
        images_dir: –ü–∞–ø–∫–∞ —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏
        labels_dir: –ü–∞–ø–∫–∞ —Å –∞–Ω–Ω–æ—Ç–∞—Ü–∏—è–º–∏
    """
    
    images_dir = Path(images_dir)
    labels_dir = Path(labels_dir)
    
    image_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.tiff'}
    
    issues = []
    stats = {'total_images': 0, 'annotated_images': 0, 'total_objects': 0}
    
    for image_path in images_dir.iterdir():
        if image_path.suffix.lower() not in image_extensions:
            continue
        
        stats['total_images'] += 1
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏
        label_path = labels_dir / f"{image_path.stem}.txt"
        
        if not label_path.exists():
            issues.append(f"–ù–µ—Ç –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏ –¥–ª—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {image_path.name}")
            continue
        
        stats['annotated_images'] += 1
        
        # –ü–æ–ª—É—á–∞–µ–º —Ä–∞–∑–º–µ—Ä—ã –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        try:
            with Image.open(image_path) as img:
                img_width, img_height = img.size
        except Exception as e:
            issues.append(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ç–∫—Ä—ã—Ç–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è {image_path.name}: {e}")
            continue
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏
        try:
            with open(label_path, 'r') as f:
                lines = f.readlines()
            
            for line_num, line in enumerate(lines, 1):
                line = line.strip()
                if not line:
                    continue
                
                parts = line.split()
                if len(parts) != 5:
                    issues.append(f"{label_path.name}:{line_num} - –Ω–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç (–æ–∂–∏–¥–∞–µ—Ç—Å—è 5 –∑–Ω–∞—á–µ–Ω–∏–π, –ø–æ–ª—É—á–µ–Ω–æ {len(parts)})")
                    continue
                
                try:
                    class_id, center_x, center_y, width, height = map(float, parts)
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–ª–∞—Å—Å
                    if not (0 <= class_id < len(DAMAGE_CLASSES)):
                        issues.append(f"{label_path.name}:{line_num} - –Ω–µ–≤–µ—Ä–Ω—ã–π ID –∫–ª–∞—Å—Å–∞: {class_id}")
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã (–¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –æ—Ç 0 –¥–æ 1)
                    if not (0 <= center_x <= 1):
                        issues.append(f"{label_path.name}:{line_num} - center_x –≤–Ω–µ –¥–∏–∞–ø–∞–∑–æ–Ω–∞ [0,1]: {center_x}")
                    if not (0 <= center_y <= 1):
                        issues.append(f"{label_path.name}:{line_num} - center_y –≤–Ω–µ –¥–∏–∞–ø–∞–∑–æ–Ω–∞ [0,1]: {center_y}")
                    if not (0 < width <= 1):
                        issues.append(f"{label_path.name}:{line_num} - width –≤–Ω–µ –¥–∏–∞–ø–∞–∑–æ–Ω–∞ (0,1]: {width}")
                    if not (0 < height <= 1):
                        issues.append(f"{label_path.name}:{line_num} - height –≤–Ω–µ –¥–∏–∞–ø–∞–∑–æ–Ω–∞ (0,1]: {height}")
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ bounding box –Ω–µ –≤—ã—Ö–æ–¥–∏—Ç –∑–∞ –≥—Ä–∞–Ω–∏—Ü—ã
                    x1 = center_x - width / 2
                    y1 = center_y - height / 2
                    x2 = center_x + width / 2
                    y2 = center_y + height / 2
                    
                    if x1 < 0 or y1 < 0 or x2 > 1 or y2 > 1:
                        issues.append(f"{label_path.name}:{line_num} - bounding box –≤—ã—Ö–æ–¥–∏—Ç –∑–∞ –≥—Ä–∞–Ω–∏—Ü—ã –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è")
                    
                    stats['total_objects'] += 1
                    
                except ValueError:
                    issues.append(f"{label_path.name}:{line_num} - –Ω–µ —É–¥–∞–µ—Ç—Å—è –ø–∞—Ä—Å–∏—Ç—å —á–∏—Å–ª–∞: {line}")
                    
        except Exception as e:
            issues.append(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏ {label_path.name}: {e}")
    
    # –í—ã–≤–æ–¥–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    print(f"\nüìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏:")
    print(f"–í—Å–µ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π: {stats['total_images']}")
    print(f"–ê–Ω–Ω–æ—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π: {stats['annotated_images']}")
    print(f"–í—Å–µ–≥–æ –æ–±—ä–µ–∫—Ç–æ–≤: {stats['total_objects']}")
    print(f"–ü–æ–∫—Ä—ã—Ç–∏–µ –∞–Ω–Ω–æ—Ç–∞—Ü–∏—è–º–∏: {stats['annotated_images']/stats['total_images']*100:.1f}%")
    
    if issues:
        print(f"\n‚ùå –ù–∞–π–¥–µ–Ω–æ {len(issues)} –ø—Ä–æ–±–ª–µ–º:")
        for issue in issues[:20]:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 20
            print(f"  - {issue}")
        if len(issues) > 20:
            print(f"  ... –∏ –µ—â–µ {len(issues) - 20} –ø—Ä–æ–±–ª–µ–º")
    else:
        print("\n‚úÖ –í—Å–µ –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏ –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã!")
    
    return len(issues) == 0

def visualize_annotations(images_dir: str, labels_dir: str, output_dir: str, max_images: int = 10):
    """
    –í–∏–∑—É–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏ –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è—Ö
    
    Args:
        images_dir: –ü–∞–ø–∫–∞ —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏
        labels_dir: –ü–∞–ø–∫–∞ —Å –∞–Ω–Ω–æ—Ç–∞—Ü–∏—è–º–∏
        output_dir: –ü–∞–ø–∫–∞ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–π
        max_images: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
    """
    
    images_dir = Path(images_dir)
    labels_dir = Path(labels_dir)
    output_dir = Path(output_dir)
    output_dir.mkdir(exist_ok=True)
    
    # –¶–≤–µ—Ç–∞ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö –∫–ª–∞—Å—Å–æ–≤
    colors = [
        (255, 0, 0),    # –∫—Ä–∞—Å–Ω—ã–π
        (0, 255, 0),    # –∑–µ–ª–µ–Ω—ã–π
        (0, 0, 255),    # —Å–∏–Ω–∏–π
        (255, 255, 0),  # –∂–µ–ª—Ç—ã–π
        (255, 0, 255),  # –ø—É—Ä–ø—É—Ä–Ω—ã–π
        (0, 255, 255),  # –≥–æ–ª—É–±–æ–π
        (255, 128, 0),  # –æ—Ä–∞–Ω–∂–µ–≤—ã–π
        (128, 0, 255),  # —Ñ–∏–æ–ª–µ—Ç–æ–≤—ã–π
    ]
    
    class_names = list(DAMAGE_CLASSES.keys())
    
    processed = 0
    
    for image_path in images_dir.iterdir():
        if processed >= max_images:
            break
        
        if image_path.suffix.lower() not in {'.jpg', '.jpeg', '.png', '.bmp'}:
            continue
        
        label_path = labels_dir / f"{image_path.stem}.txt"
        if not label_path.exists():
            continue
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
        image = cv2.imread(str(image_path))
        if image is None:
            continue
        
        height, width = image.shape[:2]
        
        # –ß–∏—Ç–∞–µ–º –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏
        with open(label_path, 'r') as f:
            lines = f.readlines()
        
        for line in lines:
            line = line.strip()
            if not line:
                continue
            
            try:
                class_id, center_x, center_y, bbox_width, bbox_height = map(float, line.split())
                class_id = int(class_id)
                
                # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ –ø–∏–∫—Å–µ–ª—å–Ω—ã–µ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã
                x1 = int((center_x - bbox_width / 2) * width)
                y1 = int((center_y - bbox_height / 2) * height)
                x2 = int((center_x + bbox_width / 2) * width)
                y2 = int((center_y + bbox_height / 2) * height)
                
                # –†–∏—Å—É–µ–º bounding box
                color = colors[class_id % len(colors)]
                cv2.rectangle(image, (x1, y1), (x2, y2), color, 2)
                
                # –î–æ–±–∞–≤–ª—è–µ–º –ø–æ–¥–ø–∏—Å—å
                label = class_names[class_id] if class_id < len(class_names) else f"class_{class_id}"
                cv2.putText(image, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)
                
            except Exception as e:
                print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏ –≤ {label_path.name}: {e}")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        output_path = output_dir / f"annotated_{image_path.name}"
        cv2.imwrite(str(output_path), image)
        
        processed += 1
        print(f"–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {image_path.name} -> {output_path.name}")
    
    print(f"\n‚úÖ –°–æ–∑–¥–∞–Ω–æ {processed} –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–π –≤ –ø–∞–ø–∫–µ {output_dir}")

def split_dataset(images_dir: str, labels_dir: str, output_dir: str, 
                 train_ratio: float = 0.7, val_ratio: float = 0.2, test_ratio: float = 0.1):
    """
    –†–∞–∑–¥–µ–ª—è–µ—Ç –¥–∞—Ç–∞—Å–µ—Ç –Ω–∞ train/val/test –Ω–∞–±–æ—Ä—ã
    
    Args:
        images_dir: –ü–∞–ø–∫–∞ —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏
        labels_dir: –ü–∞–ø–∫–∞ —Å –∞–Ω–Ω–æ—Ç–∞—Ü–∏—è–º–∏
        output_dir: –ü–∞–ø–∫–∞ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–∞–∑–¥–µ–ª–µ–Ω–Ω–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞
        train_ratio: –î–æ–ª—è —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω–æ–≥–æ –Ω–∞–±–æ—Ä–∞
        val_ratio: –î–æ–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–æ–≥–æ –Ω–∞–±–æ—Ä–∞
        test_ratio: –î–æ–ª—è —Ç–µ—Å—Ç–æ–≤–æ–≥–æ –Ω–∞–±–æ—Ä–∞
    """
    
    import random
    import shutil
    
    assert abs(train_ratio + val_ratio + test_ratio - 1.0) < 1e-6, "–°—É–º–º–∞ –¥–æ–ª–µ–π –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å —Ä–∞–≤–Ω–∞ 1.0"
    
    images_dir = Path(images_dir)
    labels_dir = Path(labels_dir)
    output_dir = Path(output_dir)
    
    # –°–æ–∑–¥–∞–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É –ø–∞–ø–æ–∫
    for split in ['train', 'val', 'test']:
        (output_dir / 'images' / split).mkdir(parents=True, exist_ok=True)
        (output_dir / 'labels' / split).mkdir(parents=True, exist_ok=True)
    
    # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —Å –∞–Ω–Ω–æ—Ç–∞—Ü–∏—è–º–∏
    image_files = []
    for image_path in images_dir.iterdir():
        if image_path.suffix.lower() in {'.jpg', '.jpeg', '.png', '.bmp'}:
            label_path = labels_dir / f"{image_path.stem}.txt"
            if label_path.exists():
                image_files.append(image_path.stem)
    
    # –ü–µ—Ä–µ–º–µ—à–∏–≤–∞–µ–º
    random.shuffle(image_files)
    
    # –†–∞–∑–¥–µ–ª—è–µ–º
    total = len(image_files)
    train_count = int(total * train_ratio)
    val_count = int(total * val_ratio)
    
    train_files = image_files[:train_count]
    val_files = image_files[train_count:train_count + val_count]
    test_files = image_files[train_count + val_count:]
    
    # –ö–æ–ø–∏—Ä—É–µ–º —Ñ–∞–π–ª—ã
    for split, files in [('train', train_files), ('val', val_files), ('test', test_files)]:
        for file_stem in files:
            # –ù–∞—Ö–æ–¥–∏–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            image_file = None
            for ext in ['.jpg', '.jpeg', '.png', '.bmp']:
                if (images_dir / f"{file_stem}{ext}").exists():
                    image_file = images_dir / f"{file_stem}{ext}"
                    break
            
            if image_file is None:
                continue
            
            # –ö–æ–ø–∏—Ä—É–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∏ –∞–Ω–Ω–æ—Ç–∞—Ü–∏—é
            shutil.copy2(image_file, output_dir / 'images' / split / image_file.name)
            shutil.copy2(labels_dir / f"{file_stem}.txt", output_dir / 'labels' / split / f"{file_stem}.txt")
    
    print(f"‚úÖ –î–∞—Ç–∞—Å–µ—Ç —Ä–∞–∑–¥–µ–ª–µ–Ω:")
    print(f"  Train: {len(train_files)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π ({len(train_files)/total*100:.1f}%)")
    print(f"  Val: {len(val_files)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π ({len(val_files)/total*100:.1f}%)")
    print(f"  Test: {len(test_files)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π ({len(test_files)/total*100:.1f}%)")
    print(f"  –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤: {output_dir}")

def main():
    import argparse
    
    parser = argparse.ArgumentParser(description='YOLO Annotation utilities')
    parser.add_argument('command', choices=['coco2yolo', 'voc2yolo', 'validate', 'visualize', 'split'])
    parser.add_argument('--images', type=str, help='–ü–∞–ø–∫–∞ —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏')
    parser.add_argument('--labels', type=str, help='–ü–∞–ø–∫–∞ —Å –∞–Ω–Ω–æ—Ç–∞—Ü–∏—è–º–∏')
    parser.add_argument('--input', type=str, help='–í—Ö–æ–¥–Ω–æ–π —Ñ–∞–π–ª/–ø–∞–ø–∫–∞')
    parser.add_argument('--output', type=str, help='–í—ã—Ö–æ–¥–Ω–∞—è –ø–∞–ø–∫–∞')
    parser.add_argument('--max-images', type=int, default=10, help='–ú–∞–∫—Å–∏–º—É–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏')
    parser.add_argument('--train-ratio', type=float, default=0.7, help='–î–æ–ª—è —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω–æ–≥–æ –Ω–∞–±–æ—Ä–∞')
    parser.add_argument('--val-ratio', type=float, default=0.2, help='–î–æ–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–æ–≥–æ –Ω–∞–±–æ—Ä–∞')
    parser.add_argument('--test-ratio', type=float, default=0.1, help='–î–æ–ª—è —Ç–µ—Å—Ç–æ–≤–æ–≥–æ –Ω–∞–±–æ—Ä–∞')
    
    args = parser.parse_args()
    
    if args.command == 'coco2yolo':
        convert_coco_to_yolo(args.input, args.images, args.output)
    elif args.command == 'voc2yolo':
        convert_pascal_voc_to_yolo(args.input, args.output)
    elif args.command == 'validate':
        validate_yolo_annotations(args.images, args.labels)
    elif args.command == 'visualize':
        visualize_annotations(args.images, args.labels, args.output, args.max_images)
    elif args.command == 'split':
        split_dataset(args.images, args.labels, args.output, 
                     args.train_ratio, args.val_ratio, args.test_ratio)

if __name__ == "__main__":
    main()
